{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with Yamnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/fbnspl/rfcx-rainforest.git\n",
    "%cd rfcx-rainforest/yamnet/\n",
    "# ! pip install tensorflow-io==0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0woGtbhsxQg"
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "# import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers.experimental.preprocessing as kp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions.augment import time_mask, freq_mask, mixup_one_hot\n",
    "from functions.metrics import LWLRAP\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data dict from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_train.pickle', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "print(data_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_val.pickle', 'rb') as f:\n",
    "    data_val = pickle.load(f)\n",
    "\n",
    "print(data_val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer learn with yamnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "    # We also generate scores at a 10 Hz frame rate.\n",
    "    # Set up the YAMNet model.\n",
    "    params = yamnet_params.Params(sample_rate=16000, patch_hop_seconds=0.1)\n",
    "    class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "    yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "    yamnet.load_weights('yamnet.h5')\n",
    "\n",
    "    # get layers from yamnet\n",
    "    layers = [l for l in yamnet.layers]\n",
    "    core_layers = layers[79:-2]\n",
    "\n",
    "    # add new imput layer\n",
    "    input_layer = tf.keras.Input(shape=(96, 64, 1), name='Input')\n",
    "    x = kp.RandomContrast(factor=0.2)(input_layer)\n",
    "\n",
    "    # attach layer again from convolutions on\n",
    "    for i, layer in enumerate(core_layers):\n",
    "        x = layer(x)\n",
    "        \n",
    "    # add new prediction layer\n",
    "    x = tf.keras.layers.Dense(24, activation='sigmoid')(x)\n",
    "\n",
    "    # construct model\n",
    "    yamnet_tl = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "    '''\n",
    "    # freeze some layers \n",
    "    for layer in yamnet_tl.layers[:50]:\n",
    "        layer.trainable =  False\n",
    "    '''\n",
    "    \n",
    "    return yamnet_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((data_train['X_train'], data_train['y_one_hot_train']))\n",
    "n_mels, n_frames, n_channels = train_dataset.element_spec[0].shape\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4096)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.cast(mel_spec, tf.float32), tf.cast(y, tf.float32)), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.squeeze(mel_spec, axis=2), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# MIXUP\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: mixup_one_hot(mel_spec, y, 0.5), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.unbatch()\n",
    "\n",
    "# SPEC AUGMENTATIONS\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (tf.roll(mel_spec, tf.random.uniform((), minval=-15, maxval=15, dtype=tf.dtypes.int32), axis=1), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.expand_dims(mel_spec, axis=2), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "print(train_dataset)\n",
    "print(data_train['X_train'].shape)\n",
    "print(data_train['y_one_hot_train'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "yamnet_tl = build_model()\n",
    "# yamnet_tl.summary()\n",
    "\n",
    "# lwrap metric\n",
    "metrics = [LWLRAP(num_classes=24), \n",
    "           tf.metrics.Precision(), \n",
    "           tf.metrics.Recall(), \n",
    "           tf.metrics.CategoricalAccuracy()]\n",
    "\n",
    "# callbacks\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_lwlrap', \n",
    "                                                     min_delta=0, \n",
    "                                                     patience=25, \n",
    "                                                     verbose=1, \n",
    "                                                     mode='auto', \n",
    "                                                     baseline=None, \n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "reduce_lro_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_lwlrap', \n",
    "                                                     factor=0.1, patience=10, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, \n",
    "                                                     cooldown=0, min_lr=0)\n",
    "\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Nadam(lr=0.001, clipnorm=1.0)\n",
    "\n",
    "# compile model\n",
    "yamnet_tl.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)\n",
    "# train model\n",
    "yamnet_tl.fit(\n",
    "              # data['X_train'], data['y_one_hot_train'],\n",
    "              train_dataset,\n",
    "              epochs=50, \n",
    "              verbose=1,\n",
    "              validation_data=(data_val['X_val'], data_val['y_one_hot_val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "yamnet_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
