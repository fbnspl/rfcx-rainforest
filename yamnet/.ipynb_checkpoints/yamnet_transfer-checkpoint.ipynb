{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with Yamnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M0woGtbhsxQg"
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers.experimental.preprocessing as kp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions.augment import time_mask, freq_mask, mixup_one_hot\n",
    "# from functions.augmentation import mixup_one_hot\n",
    "from functions.metrics import LWLRAP\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: LRAP Metric and tensorflow audio read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "def get_lrap(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict_proba(X_val)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_val = np.argmax(y_one_hot_val, axis=1)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "def get_lrap_keras(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict(X_val)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_val = np.argmax(y_one_hot_val, axis=1)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "def tf_read_audio(path, sr, target_sr):\n",
    "    # Read in the audio.\n",
    "    audio = tfio.audio.AudioIOTensor(path)\n",
    "    audio = tf.squeeze(audio[:], axis=[-1])\n",
    "    audio = tfio.audio.resample(audio, sr, target_sr)\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    audio = audio / 32768.0\n",
    "    return audio.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data dict from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['csvs_train', 'csvs_val', 'X_train', 'y_train', 'y_one_hot_train', 'X_val', 'y_val', 'y_one_hot_val', 'X_60_train', 'y_60_train', 'y_60_one_hot_train', 'X_60_val', 'y_60_val', 'y_60_one_hot_val', 'X_60_test'])\n"
     ]
    }
   ],
   "source": [
    "with open('data/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data paths and split to sets, sample rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fabianseipel/aic/data/rfcx-species-audio-detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup sample rates\n",
    "sr = 48000\n",
    "target_sr = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data dict\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all csvs\n",
    "csvs_all = sorted(glob.glob(data_path + 'train_tp/*.csv'))\n",
    "\n",
    "# split files to validation and \n",
    "data['csvs_train'], data['csvs_val'] = train_test_split(csvs_all, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get yamnet model with in-built preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "# We also generate scores at a 10 Hz frame rate.\n",
    "# Set up the YAMNet model.\n",
    "params = yamnet_params.Params(sample_rate=16000, patch_hop_seconds=0.1)\n",
    "class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get features and labels only from active 1-sec parts of true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itearet over splits\n",
    "for split in ['train', 'val']:\n",
    "    csvs = data['csvs_' + split]\n",
    "    \n",
    "    # init lists\n",
    "    X, y = [], []\n",
    "    \n",
    "    # iterate through csvs\n",
    "    for csv in tqdm(csvs, position=0, leave=True):\n",
    "\n",
    "        # get single csvs\n",
    "        gt = pd.read_csv(csv, index_col=0).to_numpy()\n",
    "\n",
    "        # get frames and classes where true positives are\n",
    "        specs, frames = gt.nonzero()\n",
    "\n",
    "        # load feature embeddings\n",
    "        audio = tf_read_audio(data_path + f'train/{Path(csv).stem}.flac', 48000, 16000)\n",
    "        audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "\n",
    "        # iterate through active tp frames\n",
    "        for spec, frame in zip(specs, frames):\n",
    "            audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "            _, _, spec = yamnet(audio_frame)\n",
    "            spec = spec.numpy()\n",
    "            spec = np.expand_dims(spec, axis=-1)\n",
    "            X.append(spec)\n",
    "            y.append(gt[:, frame])\n",
    "\n",
    "\n",
    "    # convert to numpy array and one-hot\n",
    "    data['X_' + split] = np.array(X)\n",
    "    data['y_' + split] = np.argmax(np.array(y), axis=1)\n",
    "    data['y_one_hot_' + split] = np.array(y)\n",
    "    \n",
    "    print(data['X_' + split].shape, data['y_' + split].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get features and labels on whole 60-seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itearet over splits\n",
    "for split in ['train', 'val']:\n",
    "    csvs = data['csvs_' + split]\n",
    "    \n",
    "    # init lists\n",
    "    X, y = [], []\n",
    "    \n",
    "    # iterate through csvs\n",
    "    for csv in tqdm(csvs, position=0, leave=True):\n",
    "\n",
    "        # get single csvs\n",
    "        gt = pd.read_csv(csv, index_col=0).to_numpy()\n",
    "        print(gt.shape)\n",
    "        y.append(gt)\n",
    "        \n",
    "        # read audio\n",
    "        audio = tf_read_audio(data_path + f'train/{Path(csv).stem}.flac', 48000, 16000)\n",
    "        audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "        X_list = []\n",
    "\n",
    "        # iterate through all frames\n",
    "        for frame in range(audio_frames.shape[1]):\n",
    "            audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "            _, _, spec = yamnet(audio_frame)\n",
    "            spec = spec.numpy()\n",
    "            spec = np.expand_dims(spec, axis=-1)\n",
    "            X_list.append(spec)\n",
    "\n",
    "        X_list = np.array(X_list)\n",
    "        X.append(X_list)\n",
    "\n",
    "\n",
    "    # convert to numpy array and one-hot\n",
    "    data['X_60_' + split] = np.array(X)\n",
    "    data['y_60_' + split] = np.argmax(np.array(y), axis=1)\n",
    "    data['y_60_one_hot_' + split] = np.array(y)\n",
    "    \n",
    "    print(data['X_60_' + split].shape, data['y_60_one_hot_' + split].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init lists\n",
    "X = []\n",
    "\n",
    "# get all true positive csvs\n",
    "files = sorted(glob.glob(data_path + 'test/*.flac'))\n",
    "\n",
    "# iterate through csvs\n",
    "for file in tqdm(files, position=0, leave=True):\n",
    "    \n",
    "    # load feature embeddings\n",
    "    audio = tf_read_audio(file, 48000, 16000)\n",
    "    audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "    specs = []\n",
    "    \n",
    "    # iterate through all frames\n",
    "    for frame in range(audio_frames.shape[1]):\n",
    "        audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "        _, _, spec = yamnet(audio_frame)\n",
    "        spec = spec.numpy()\n",
    "        spec = np.expand_dims(spec, axis=-1)\n",
    "        specs.append(spec)\n",
    "        \n",
    "    specs = np.array(specs)\n",
    "    X.append(specs)\n",
    "\n",
    "# convert to numpy array and one-hot\n",
    "data['X_60_test'] = np.array(X)\n",
    "\n",
    "print(data['X_60_test'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save all data dict to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('data/data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save train/val data dict to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {}\n",
    "data_train['X_train'] = data['X_train']\n",
    "data_train['y_train'] = data['y_train']\n",
    "data_train['y_one_hot_train'] = data['y_one_hot_train']\n",
    "\n",
    "with open('data/data_train.pickle', 'wb') as f:\n",
    "    pickle.dump(data_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "data_val = {}\n",
    "data_val['X_val'] = data['X_val']\n",
    "data_val['y_val'] = data['y_val']\n",
    "data_val['y_one_hot_val'] = data['y_one_hot_val']\n",
    "\n",
    "with open('data/data_val.pickle', 'wb') as f:\n",
    "    pickle.dump(data_val, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get yamnet architecture with pretrained weights and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "    # We also generate scores at a 10 Hz frame rate.\n",
    "    # Set up the YAMNet model.\n",
    "    params = yamnet_params.Params(sample_rate=16000, patch_hop_seconds=0.1)\n",
    "    class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "    yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "    yamnet.load_weights('yamnet.h5')\n",
    "\n",
    "    # get layers from yamnet\n",
    "    layers = [l for l in yamnet.layers]\n",
    "    core_layers = layers[79:-2]\n",
    "\n",
    "    # add new imput layer\n",
    "    input_layer = tf.keras.Input(shape=(96, 64, 1), name='Input')\n",
    "    x = kp.RandomContrast(factor=0.2)(input_layer)\n",
    "\n",
    "    # attach layer again from convolutions on\n",
    "    for i, layer in enumerate(core_layers):\n",
    "        x = layer(x)\n",
    "        \n",
    "    # add new prediction layer\n",
    "    x = tf.keras.layers.Dense(24, activation='sigmoid')(x)\n",
    "\n",
    "    # construct model\n",
    "    yamnet_tl = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "    '''\n",
    "    # freeze some layers \n",
    "    for layer in yamnet_tl.layers[:50]:\n",
    "        layer.trainable =  False\n",
    "    '''\n",
    "    \n",
    "    return yamnet_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ShuffleDataset shapes: ((96, 64, 1), (24,)), types: (tf.float32, tf.float64)>\n",
      "<ParallelMapDataset shapes: ((96, 64), (24,)), types: (tf.float32, tf.float64)>\n",
      "<BatchDataset shapes: ((None, 96, 64), (None, 24)), types: (tf.float32, tf.float32)>\n",
      "<_UnbatchDataset shapes: ((None, 96, 64), (None, 24)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, None, 96, 64), (None, None, 24)), types: (tf.float32, tf.float32)>\n",
      "(3287, 96, 64, 1)\n",
      "(3287, 24)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "condition [32,1], then [], and else [32,96,64] must be broadcastable\n\t [[{{node SelectV2}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: condition [32,1], then [], and else [32,96,64] must be broadcastable\n\t [[{{node SelectV2}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fbcf7af6315f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_one_hot_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: condition [32,1], then [], and else [32,96,64] must be broadcastable\n\t [[{{node SelectV2}}]]"
     ]
    }
   ],
   "source": [
    "# autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((data['X_train'], data['y_one_hot_train']))\n",
    "n_mels, n_frames, n_channels = train_dataset.element_spec[0].shape\n",
    "# print(train_dataset)\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=2048)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.squeeze(mel_spec, axis=2), y), num_parallel_calls=AUTOTUNE)\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.cast(mel_spec, tf.float32), tf.cast(y, tf.float32)), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.roll(mel_spec, tf.random.uniform((), minval=-15, maxval=15, dtype=tf.dtypes.int32), axis=1), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(32)\n",
    "print(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: mixup_one_hot(mel_spec, y, 0.5), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.unbatch()\n",
    "print(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "print(train_dataset)\n",
    "print(data['X_train'].shape)\n",
    "print(data['y_one_hot_train'].shape)\n",
    "\n",
    "for el in train_dataset:\n",
    "    print(el)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_one_hot(x, l, beta):\n",
    "    \"\"\"\n",
    "    see https://arxiv.org/pdf/1710.09412.pdf\n",
    "    Apply mixup to a batch of spectrograms.\n",
    "    Args:\n",
    "      x: An audio spectogram.\n",
    "      l: One-hot encoded ground truth.\n",
    "      param: Parameter of time masking.\n",
    "    Returns:\n",
    "      A tensor of batched spectrograms.\n",
    "    \"\"\"\n",
    "    print(l.shape)\n",
    "    print(x.shape)\n",
    "    \n",
    "    mix = tfd.Beta(beta, beta).sample([tf.shape(x)[0], 1, 1, 1])\n",
    "    mix = tf.maximum(mix, 1 - mix)\n",
    "    print(mix.shape)\n",
    "    \n",
    "    xmix = x * mix + x[::-1] * (1 - mix)\n",
    "    \n",
    "    \n",
    "    lmix = l * mix[:, :, 0] + l[::-1] * (1 - mix[:, :, 0])\n",
    "\n",
    "    print(lmix.shape)\n",
    "    print(xmix.shape)\n",
    "\n",
    "    return xmix, lmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand = np.random.rand(64, 96, 64, 1)\n",
    "y_rand = np.random.rand(64, 24)\n",
    "random_dataset = tf.data.Dataset.from_tensor_slices((X_rand, y_rand))\n",
    "random_dataset = random_dataset.map(lambda mel_spec, y: (tf.cast(mel_spec, tf.float32), tf.cast(y, tf.float32)), num_parallel_calls=AUTOTUNE)\n",
    "random_dataset = random_dataset.batch(32)\n",
    "random_dataset = random_dataset.map(lambda mel_spec, y: mixup_one_hot(mel_spec, y, 0.5), num_parallel_calls=AUTOTUNE)\n",
    "random_dataset = random_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "print(random_dataset)\n",
    "for el in random_dataset:\n",
    "    print(el)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "yamnet_tl = build_model()\n",
    "# yamnet_tl.summary()\n",
    "\n",
    "# lwrap metric\n",
    "metrics = [LWLRAP(num_classes=24), \n",
    "           tf.metrics.Precision(), \n",
    "           tf.metrics.Recall(), \n",
    "           tf.metrics.CategoricalAccuracy()]\n",
    "\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Nadam(lr=0.01, clipnorm=1.0)\n",
    "\n",
    "# compile model\n",
    "yamnet_tl.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)\n",
    "# train model\n",
    "yamnet_tl.fit(\n",
    "              # data['X_train'], data['y_one_hot_train'],\n",
    "              train_dataset,\n",
    "              epochs=50, \n",
    "              verbose=1,\n",
    "              validation_data=(data['X_val'], data['y_one_hot_val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict on 60-seconds features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val = []\n",
    "X_60_val = data['X_60_val']\n",
    "\n",
    "for n in tqdm(range(X_60_val.shape[0]), position=0, leave=True):\n",
    "    y_prob = yamnet_tl.predict(X_60_val[n, :])\n",
    "    y_prob_val.append(y_prob)\n",
    "\n",
    "    \n",
    "y_prob_val = np.array(y_prob_val)\n",
    "y_prob_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate probabilities over 60-sec with max an mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val_max = np.max(y_prob_val, axis=1)\n",
    "y_prob_val_mean = np.mean(y_prob_val, axis=1)\n",
    "y_prob_val_min = np.min(y_prob_val, axis=1)\n",
    "y_prob_val_max.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ground truth, aggregate over 60-sec with max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_60_one_hot_val = data['y_60_one_hot_val']\n",
    "y_60_one_hot_val_max = np.max(y_60_one_hot_val, axis=2)\n",
    "y_60_one_hot_val_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LRAP Max  : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_max))\n",
    "print('LRAP Mean : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_mean))\n",
    "print('LRAP Min. : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = yamnet_tl.predict(X_train[3, :])\n",
    "y_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_test_prob)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "yamnet_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
