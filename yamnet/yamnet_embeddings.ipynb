{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save yamnet embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "import librosa\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fabianseipel/aic/data/rfcx-species-audio-detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "# We also generate scores at a 10 Hz frame rate.\n",
    "params = yamnet_params.Params(sample_rate=48000, patch_hop_seconds=0.1)\n",
    "        \n",
    "# Set up the YAMNet model.\n",
    "class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet.h5')\n",
    "\n",
    "# save embedding per 1s frame (predict middle 0.96s)\n",
    "def save_yamnet_embeddings(f):\n",
    "    # construct output path\n",
    "    savepath = './embeddings/' + Path(f).parts[-2] + '/' + str(Path(f).stem) + '.npy' \n",
    "    \n",
    "    # save embeddings if not exist already\n",
    "    if not os.path.exists(savepath):      \n",
    "        audio = tfio.audio.AudioIOTensor(f)\n",
    "        audio = tf.squeeze(audio[:], axis=[-1])\n",
    "        frames = librosa.util.frame(audio.numpy(), frame_length=48000, hop_length=48000)\n",
    "        n_frames = frames.shape[1]\n",
    "        embeddings = []\n",
    "\n",
    "        for n in range(n_frames):\n",
    "            # get mid 0.96 seconds\n",
    "            audio_frame = frames[int(0.02*48000):-int(0.02*48000), n]\n",
    "            _, emb, _ = yamnet(audio_frame)\n",
    "            embeddings.append(emb.numpy())\n",
    "\n",
    "        # save embeddings\n",
    "        emb_array = np.squeeze(np.array(embeddings))\n",
    "        np.save(savepath, emb_array)\n",
    "\n",
    "# script\n",
    "test_files = glob.glob(data_path + 'test/*.flac')\n",
    "train_files = glob.glob(data_path + 'train/*.flac')\n",
    "files = test_files + train_files\n",
    "\n",
    "# make folders\n",
    "os.makedirs('./embeddings/', exist_ok=True)\n",
    "os.makedirs('./embeddings/test', exist_ok=True)\n",
    "os.makedirs('./embeddings/train', exist_ok=True)\n",
    "\n",
    "'''\n",
    "for f in tqdm.tqdm(files):\n",
    "    save_yamnet_embeddings(f)\n",
    "'''\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
