{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with Yamnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/fbnspl/rfcx-rainforest.git\n",
    "%cd rfcx-rainforest/yamnet/\n",
    "! pip install tensorflow-io==0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0woGtbhsxQg"
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers.experimental.preprocessing as kp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions.augment import time_mask, freq_mask, mixup_one_hot\n",
    "from functions.metrics import LWLRAP\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions: LRAP Metric and tensorflow audio read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "def get_lrap(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict_proba(X_val)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_val = np.argmax(y_one_hot_val, axis=1)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "def get_lrap_keras(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict(X_val)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_val = np.argmax(y_one_hot_val, axis=1)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "def tf_read_audio(path, sr, target_sr):\n",
    "    # Read in the audio.\n",
    "    audio = tfio.audio.AudioIOTensor(path)\n",
    "    audio = tf.squeeze(audio[:], axis=[-1])\n",
    "    audio = tfio.audio.resample(audio, sr, target_sr)\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    audio = audio / 32768.0\n",
    "    return audio.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data dict from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_train.pickle', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "print(data_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data_val.pickle', 'rb') as f:\n",
    "    data_val = pickle.load(f)\n",
    "\n",
    "print(data_val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data paths and split to sets, sample rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fabianseipel/aic/data/rfcx-species-audio-detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup sample rates\n",
    "sr = 48000\n",
    "target_sr = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data dict\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all csvs\n",
    "csvs_all = sorted(glob.glob(data_path + 'train_tp/*.csv'))\n",
    "\n",
    "# split files to validation and \n",
    "data['csvs_train'], data['csvs_val'] = train_test_split(csvs_all, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get yamnet model with in-built preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "# We also generate scores at a 10 Hz frame rate.\n",
    "# Set up the YAMNet model.\n",
    "params = yamnet_params.Params(sample_rate=16000, patch_hop_seconds=0.1)\n",
    "class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get features and labels only from active 1-sec parts of true positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itearet over splits\n",
    "for split in ['train', 'val']:\n",
    "    csvs = data['csvs_' + split]\n",
    "    \n",
    "    # init lists\n",
    "    X, y = [], []\n",
    "    \n",
    "    # iterate through csvs\n",
    "    for csv in tqdm(csvs, position=0, leave=True):\n",
    "\n",
    "        # get single csvs\n",
    "        gt = pd.read_csv(csv, index_col=0).to_numpy()\n",
    "\n",
    "        # get frames and classes where true positives are\n",
    "        specs, frames = gt.nonzero()\n",
    "\n",
    "        # load feature embeddings\n",
    "        audio = tf_read_audio(data_path + f'train/{Path(csv).stem}.flac', 48000, 16000)\n",
    "        audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "\n",
    "        # iterate through active tp frames\n",
    "        for spec, frame in zip(specs, frames):\n",
    "            audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "            _, _, spec = yamnet(audio_frame)\n",
    "            spec = spec.numpy()\n",
    "            spec = np.expand_dims(spec, axis=-1)\n",
    "            X.append(spec)\n",
    "            y.append(gt[:, frame])\n",
    "\n",
    "\n",
    "    # convert to numpy array and one-hot\n",
    "    data['X_' + split] = np.array(X)\n",
    "    data['y_' + split] = np.argmax(np.array(y), axis=1)\n",
    "    data['y_one_hot_' + split] = np.array(y)\n",
    "    \n",
    "    print(data['X_' + split].shape, data['y_' + split].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get features and labels on whole 60-seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itearet over splits\n",
    "for split in ['train', 'val']:\n",
    "    csvs = data['csvs_' + split]\n",
    "    \n",
    "    # init lists\n",
    "    X, y = [], []\n",
    "    \n",
    "    # iterate through csvs\n",
    "    for csv in tqdm(csvs, position=0, leave=True):\n",
    "\n",
    "        # get single csvs\n",
    "        gt = pd.read_csv(csv, index_col=0).to_numpy()\n",
    "        print(gt.shape)\n",
    "        y.append(gt)\n",
    "        \n",
    "        # read audio\n",
    "        audio = tf_read_audio(data_path + f'train/{Path(csv).stem}.flac', 48000, 16000)\n",
    "        audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "        X_list = []\n",
    "\n",
    "        # iterate through all frames\n",
    "        for frame in range(audio_frames.shape[1]):\n",
    "            audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "            _, _, spec = yamnet(audio_frame)\n",
    "            spec = spec.numpy()\n",
    "            spec = np.expand_dims(spec, axis=-1)\n",
    "            X_list.append(spec)\n",
    "\n",
    "        X_list = np.array(X_list)\n",
    "        X.append(X_list)\n",
    "\n",
    "\n",
    "    # convert to numpy array and one-hot\n",
    "    data['X_60_' + split] = np.array(X)\n",
    "    data['y_60_' + split] = np.argmax(np.array(y), axis=1)\n",
    "    data['y_60_one_hot_' + split] = np.array(y)\n",
    "    \n",
    "    print(data['X_60_' + split].shape, data['y_60_one_hot_' + split].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init lists\n",
    "X = []\n",
    "\n",
    "# get all true positive csvs\n",
    "files = sorted(glob.glob(data_path + 'test/*.flac'))\n",
    "\n",
    "# iterate through csvs\n",
    "for file in tqdm(files, position=0, leave=True):\n",
    "    \n",
    "    # load feature embeddings\n",
    "    audio = tf_read_audio(file, 48000, 16000)\n",
    "    audio_frames = librosa.util.frame(audio, frame_length=16000, hop_length=16000)\n",
    "    specs = []\n",
    "    \n",
    "    # iterate through all frames\n",
    "    for frame in range(audio_frames.shape[1]):\n",
    "        audio_frame = audio_frames[int(0.02*16000):-int(0.02*16000), frame]\n",
    "        _, _, spec = yamnet(audio_frame)\n",
    "        spec = spec.numpy()\n",
    "        spec = np.expand_dims(spec, axis=-1)\n",
    "        specs.append(spec)\n",
    "        \n",
    "    specs = np.array(specs)\n",
    "    X.append(specs)\n",
    "\n",
    "# convert to numpy array and one-hot\n",
    "data['X_60_test'] = np.array(X)\n",
    "\n",
    "print(data['X_60_test'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save all data dict to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('data/data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save train/val data dict to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {}\n",
    "data_train['X_train'] = data['X_train']\n",
    "data_train['y_train'] = data['y_train']\n",
    "data_train['y_one_hot_train'] = data['y_one_hot_train']\n",
    "\n",
    "with open('data/data_train.pickle', 'wb') as f:\n",
    "    pickle.dump(data_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "data_val = {}\n",
    "data_val['X_val'] = data['X_val']\n",
    "data_val['y_val'] = data['y_val']\n",
    "data_val['y_one_hot_val'] = data['y_one_hot_val']\n",
    "\n",
    "with open('data/data_val.pickle', 'wb') as f:\n",
    "    pickle.dump(data_val, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer learn with yamnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # The graph is designed for a sampling rate of 16 kHz, but higher rates should work too.\n",
    "    # We also generate scores at a 10 Hz frame rate.\n",
    "    # Set up the YAMNet model.\n",
    "    params = yamnet_params.Params(sample_rate=16000, patch_hop_seconds=0.1)\n",
    "    class_names = yamnet_model.class_names('yamnet_class_map.csv')\n",
    "    yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "    yamnet.load_weights('yamnet.h5')\n",
    "\n",
    "    # get layers from yamnet\n",
    "    layers = [l for l in yamnet.layers]\n",
    "    core_layers = layers[79:-2]\n",
    "\n",
    "    # add new imput layer\n",
    "    input_layer = tf.keras.Input(shape=(96, 64, 1), name='Input')\n",
    "    x = kp.RandomContrast(factor=0.2)(input_layer)\n",
    "\n",
    "    # attach layer again from convolutions on\n",
    "    for i, layer in enumerate(core_layers):\n",
    "        x = layer(x)\n",
    "        \n",
    "    # add new prediction layer\n",
    "    x = tf.keras.layers.Dense(24, activation='sigmoid')(x)\n",
    "\n",
    "    # construct model\n",
    "    yamnet_tl = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "    '''\n",
    "    # freeze some layers \n",
    "    for layer in yamnet_tl.layers[:50]:\n",
    "        layer.trainable =  False\n",
    "    '''\n",
    "    \n",
    "    return yamnet_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((data_train['X_train'], data_train['y_one_hot_train']))\n",
    "n_mels, n_frames, n_channels = train_dataset.element_spec[0].shape\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4096)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.cast(mel_spec, tf.float32), tf.cast(y, tf.float32)), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.squeeze(mel_spec, axis=2), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# MIXUP\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: mixup_one_hot(mel_spec, y, 0.5), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.unbatch()\n",
    "\n",
    "# SPEC AUGMENTATIONS\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (tf.roll(mel_spec, tf.random.uniform((), minval=-15, maxval=15, dtype=tf.dtypes.int32), axis=1), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (time_mask(mel_spec, param=int(n_frames * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "# train_dataset = train_dataset.map(lambda mel_spec, y: (freq_mask(mel_spec, param=int(n_mels * 0.1)), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(lambda mel_spec, y: (tf.expand_dims(mel_spec, axis=2), y), num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "print(train_dataset)\n",
    "print(data_train['X_train'].shape)\n",
    "print(data_train['y_one_hot_train'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "yamnet_tl = build_model()\n",
    "# yamnet_tl.summary()\n",
    "\n",
    "# lwrap metric\n",
    "metrics = [LWLRAP(num_classes=24), \n",
    "           tf.metrics.Precision(), \n",
    "           tf.metrics.Recall(), \n",
    "           tf.metrics.CategoricalAccuracy()]\n",
    "\n",
    "# callbacks\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_lwlrap', \n",
    "                                                     min_delta=0, \n",
    "                                                     patience=25, \n",
    "                                                     verbose=1, \n",
    "                                                     mode='auto', \n",
    "                                                     baseline=None, \n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "reduce_lro_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_lwlrap', \n",
    "                                                     factor=0.1, patience=10, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, \n",
    "                                                     cooldown=0, min_lr=0)\n",
    "\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.Nadam(lr=0.001, clipnorm=1.0)\n",
    "\n",
    "# compile model\n",
    "yamnet_tl.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)\n",
    "# train model\n",
    "yamnet_tl.fit(\n",
    "              # data['X_train'], data['y_one_hot_train'],\n",
    "              train_dataset,\n",
    "              epochs=50, \n",
    "              verbose=1,\n",
    "              validation_data=(data_val['X_val'], data_val['y_one_hot_val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predict on 60-seconds features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val = []\n",
    "X_60_val = data['X_60_val']\n",
    "\n",
    "for n in tqdm(range(X_60_val.shape[0]), position=0, leave=True):\n",
    "    y_prob = yamnet_tl.predict(X_60_val[n, :])\n",
    "    y_prob_val.append(y_prob)\n",
    "\n",
    "    \n",
    "y_prob_val = np.array(y_prob_val)\n",
    "y_prob_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate probabilities over 60-sec with max an mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_val_max = np.max(y_prob_val, axis=1)\n",
    "y_prob_val_mean = np.mean(y_prob_val, axis=1)\n",
    "y_prob_val_min = np.min(y_prob_val, axis=1)\n",
    "y_prob_val_max.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ground truth, aggregate over 60-sec with max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_60_one_hot_val = data['y_60_one_hot_val']\n",
    "y_60_one_hot_val_max = np.max(y_60_one_hot_val, axis=2)\n",
    "y_60_one_hot_val_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LRAP Max  : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_max))\n",
    "print('LRAP Mean : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_mean))\n",
    "print('LRAP Min. : %s' % label_ranking_average_precision_score(y_60_one_hot_val_max, y_prob_val_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = yamnet_tl.predict(X_train[3, :])\n",
    "y_test_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(y_test_prob)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "yamnet_visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
