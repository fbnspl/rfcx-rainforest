{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify yamnet embeddings with sklearn methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get only active seconds from true positives and corresponding embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1132/1132 [00:08<00:00, 134.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4122, 1024) (4122,)\n"
     ]
    }
   ],
   "source": [
    "# init lists\n",
    "X, y = [], []\n",
    "\n",
    "# get all true positive csvs\n",
    "csvs = sorted(glob.glob('./rfcx-species-audio-detection/train_tp/*.csv'))\n",
    "\n",
    "# iterate through csvs\n",
    "for csv in tqdm(csvs):\n",
    "    \n",
    "    # get single csvs\n",
    "    gt = pd.read_csv(csv, index_col=0).to_numpy()\n",
    "    \n",
    "    # get frames and classes where true positives are\n",
    "    specs, frames = gt.nonzero()\n",
    "\n",
    "    # load feature embeddings\n",
    "    emb = np.load(f'embeddings/yamnet/train/{Path(csv).stem}.npy')\n",
    "    \n",
    "    # iterate through active tp frames\n",
    "    for spec, frame in zip(specs, frames):\n",
    "        X.append(emb[frame, :])\n",
    "        y.append(gt[:, frame])\n",
    "\n",
    "\n",
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# convert one-hot to argmax\n",
    "y_one_hot = y\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1992/1992 [00:03<00:00, 645.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 60, 1024)\n"
     ]
    }
   ],
   "source": [
    "# init lists\n",
    "X_test = []\n",
    "\n",
    "# get all true positive csvs\n",
    "files = sorted(glob.glob('./embeddings/yamnet/test/*.npy'))\n",
    "\n",
    "# iterate through csvs\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    # load feature embeddings\n",
    "    emb = np.load(file)\n",
    "    X_test.append(emb)\n",
    "    \n",
    "# convert to numpy array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tensorflow dataset from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((1024,), (24,)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y_one_hot))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make X, y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=11)\n",
    "X_train, X_val, y_one_hot_train, y_one_hot_val = train_test_split(X, y_one_hot, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRAP Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "def get_lrap(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict_proba(X_val)\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "def get_lrap_keras(X_val, y_one_hot_val, clf):\n",
    "    y_prob = clf.predict(X_val)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    print('LRAP: %s' % label_ranking_average_precision_score(y_one_hot_val, y_prob))\n",
    "    print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           2.7210            7.43m\n",
      "         2           2.5605            7.37m\n",
      "         3           2.4388            7.31m\n",
      "         4           2.3415            7.22m\n",
      "         5           2.2546            7.13m\n",
      "         6           2.1782            7.06m\n",
      "         7           2.1110            7.02m\n",
      "         8           2.0373            6.97m\n",
      "         9           1.9720            6.99m\n",
      "        10           1.9088            7.00m\n",
      "        20           1.4930            6.24m\n",
      "        30           1.2263            5.52m\n",
      "        40           1.0332            4.71m\n",
      "        50           0.8838            3.96m\n",
      "        60           0.7669            3.17m\n",
      "        70           0.6713            2.40m\n",
      "        80           0.5902            1.60m\n",
      "        90           0.5221           48.09s\n",
      "       100           0.4638            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_xgb = GradientBoostingClassifier(random_state=0, verbose=1)\n",
    "clf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP: 0.44245763985637226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.12      0.15        16\n",
      "           1       0.18      0.08      0.11        25\n",
      "           2       0.33      0.27      0.30        26\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.32      0.27      0.29        41\n",
      "           5       0.23      0.05      0.09        55\n",
      "           6       0.22      0.10      0.14        39\n",
      "           7       0.25      0.11      0.15        56\n",
      "           8       0.28      0.49      0.36        49\n",
      "           9       0.20      0.13      0.16        38\n",
      "          10       0.21      0.10      0.13        42\n",
      "          11       0.07      0.04      0.05        26\n",
      "          12       0.18      0.14      0.16        42\n",
      "          13       0.35      0.35      0.35        17\n",
      "          14       0.15      0.09      0.11        23\n",
      "          15       0.37      0.35      0.36        48\n",
      "          16       0.21      0.15      0.17        27\n",
      "          17       0.29      0.32      0.30       101\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.46      0.24      0.32        25\n",
      "          20       0.18      0.12      0.14        60\n",
      "          21       0.10      0.04      0.06        25\n",
      "          22       0.00      0.00      0.00        23\n",
      "          23       0.32      0.70      0.44       193\n",
      "\n",
      "    accuracy                           0.28      1031\n",
      "   macro avg       0.21      0.18      0.18      1031\n",
      "weighted avg       0.25      0.28      0.24      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get metrics for gradient boosting\n",
    "get_lrap(X_val, y_one_hot_val, clf_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(random_state=8)\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP: 0.20324118978338013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.12      0.11        16\n",
      "           1       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.19      0.15      0.17        20\n",
      "           4       0.29      0.17      0.22        41\n",
      "           5       0.15      0.09      0.11        55\n",
      "           6       0.12      0.13      0.12        39\n",
      "           7       0.09      0.07      0.08        56\n",
      "           8       0.25      0.33      0.28        49\n",
      "           9       0.15      0.18      0.16        38\n",
      "          10       0.13      0.14      0.13        42\n",
      "          11       0.09      0.08      0.08        26\n",
      "          12       0.09      0.10      0.09        42\n",
      "          13       0.16      0.18      0.17        17\n",
      "          14       0.09      0.04      0.06        23\n",
      "          15       0.15      0.12      0.14        48\n",
      "          16       0.05      0.07      0.06        27\n",
      "          17       0.19      0.21      0.20       101\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.17      0.16      0.16        25\n",
      "          20       0.13      0.13      0.13        60\n",
      "          21       0.11      0.16      0.13        25\n",
      "          22       0.07      0.09      0.08        23\n",
      "          23       0.32      0.34      0.33       193\n",
      "\n",
      "    accuracy                           0.17      1031\n",
      "   macro avg       0.13      0.13      0.13      1031\n",
      "weighted avg       0.17      0.17      0.17      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get metrics for gradient boosting\n",
    "get_lrap(X_val, y_one_hot_val, clf_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', probability=True, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svc = SVC(gamma='auto', probability=True, verbose=1)\n",
    "clf_svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP: 0.47440168500060803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        16\n",
      "           1       1.00      0.08      0.15        25\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.51      0.44      0.47        41\n",
      "           5       1.00      0.13      0.23        55\n",
      "           6       0.00      0.00      0.00        39\n",
      "           7       0.00      0.00      0.00        56\n",
      "           8       0.37      0.63      0.47        49\n",
      "           9       1.00      0.05      0.10        38\n",
      "          10       0.43      0.21      0.29        42\n",
      "          11       0.00      0.00      0.00        26\n",
      "          12       0.82      0.33      0.47        42\n",
      "          13       0.00      0.00      0.00        17\n",
      "          14       1.00      0.17      0.30        23\n",
      "          15       1.00      0.10      0.19        48\n",
      "          16       1.00      0.19      0.31        27\n",
      "          17       0.88      0.07      0.13       101\n",
      "          18       1.00      0.07      0.13        14\n",
      "          19       0.00      0.00      0.00        25\n",
      "          20       1.00      0.02      0.03        60\n",
      "          21       0.00      0.00      0.00        25\n",
      "          22       0.00      0.00      0.00        23\n",
      "          23       0.23      0.98      0.37       193\n",
      "\n",
      "    accuracy                           0.29      1031\n",
      "   macro avg       0.51      0.17      0.18      1031\n",
      "weighted avg       0.51      0.29      0.21      1031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabianseipel/opt/miniconda3/envs/rainforest/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_lrap(X_val, y_one_hot_val, clf_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify with Vanilla Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 5.3845 - accuracy: 0.1660 - val_loss: 3.5790 - val_accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 3.0430 - accuracy: 0.2155 - val_loss: 2.6400 - val_accuracy: 0.2493\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.7810 - accuracy: 0.2268 - val_loss: 2.5402 - val_accuracy: 0.2580\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.7142 - accuracy: 0.2478 - val_loss: 2.5247 - val_accuracy: 0.2502\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.7017 - accuracy: 0.2478 - val_loss: 2.5641 - val_accuracy: 0.2609\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5686 - accuracy: 0.2698 - val_loss: 2.5050 - val_accuracy: 0.2755\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.5748 - accuracy: 0.2695 - val_loss: 2.4291 - val_accuracy: 0.2881\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4871 - accuracy: 0.2815 - val_loss: 2.4954 - val_accuracy: 0.2735\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.4848 - accuracy: 0.2863 - val_loss: 2.3886 - val_accuracy: 0.2842\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.4193 - accuracy: 0.2951 - val_loss: 2.3870 - val_accuracy: 0.2949\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.3934 - accuracy: 0.3125 - val_loss: 2.4394 - val_accuracy: 0.2861\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.3896 - accuracy: 0.3164 - val_loss: 2.4251 - val_accuracy: 0.2929\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.3466 - accuracy: 0.3203 - val_loss: 2.3802 - val_accuracy: 0.2968\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3135 - accuracy: 0.3300 - val_loss: 2.3786 - val_accuracy: 0.2958\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.3074 - accuracy: 0.3306 - val_loss: 2.4337 - val_accuracy: 0.2939\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.3053 - accuracy: 0.3410 - val_loss: 2.3506 - val_accuracy: 0.3065\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2776 - accuracy: 0.3407 - val_loss: 2.3245 - val_accuracy: 0.3104\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2513 - accuracy: 0.3442 - val_loss: 2.3383 - val_accuracy: 0.3201\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2278 - accuracy: 0.3562 - val_loss: 2.3446 - val_accuracy: 0.3152\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.2098 - accuracy: 0.3617 - val_loss: 2.3228 - val_accuracy: 0.3191\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1952 - accuracy: 0.3598 - val_loss: 2.3135 - val_accuracy: 0.3104\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1879 - accuracy: 0.3591 - val_loss: 2.3696 - val_accuracy: 0.2997\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1655 - accuracy: 0.3633 - val_loss: 2.3629 - val_accuracy: 0.3046\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1578 - accuracy: 0.3656 - val_loss: 2.3248 - val_accuracy: 0.3210\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1311 - accuracy: 0.3746 - val_loss: 2.3500 - val_accuracy: 0.3210\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.1225 - accuracy: 0.3795 - val_loss: 2.3090 - val_accuracy: 0.3327\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1199 - accuracy: 0.3863 - val_loss: 2.2917 - val_accuracy: 0.3259\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.1090 - accuracy: 0.3882 - val_loss: 2.3174 - val_accuracy: 0.3191\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 2.0989 - accuracy: 0.3788 - val_loss: 2.3389 - val_accuracy: 0.3113\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0820 - accuracy: 0.3808 - val_loss: 2.3060 - val_accuracy: 0.3191\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 2.0284 - accuracy: 0.3944 - val_loss: 2.2845 - val_accuracy: 0.3269\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0482 - accuracy: 0.3918 - val_loss: 2.3248 - val_accuracy: 0.3220\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0557 - accuracy: 0.3895 - val_loss: 2.3019 - val_accuracy: 0.3240\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0864 - accuracy: 0.3950 - val_loss: 2.3363 - val_accuracy: 0.3307\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0195 - accuracy: 0.4018 - val_loss: 2.3020 - val_accuracy: 0.3230\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 2.0122 - accuracy: 0.4038 - val_loss: 2.3041 - val_accuracy: 0.3288\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9721 - accuracy: 0.4099 - val_loss: 2.3206 - val_accuracy: 0.3172\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.9988 - accuracy: 0.4067 - val_loss: 2.3525 - val_accuracy: 0.3133\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9619 - accuracy: 0.4190 - val_loss: 2.3434 - val_accuracy: 0.3201\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9718 - accuracy: 0.4173 - val_loss: 2.2788 - val_accuracy: 0.3443\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9499 - accuracy: 0.4138 - val_loss: 2.3396 - val_accuracy: 0.3278\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9591 - accuracy: 0.4154 - val_loss: 2.4147 - val_accuracy: 0.3240\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.9604 - accuracy: 0.4135 - val_loss: 2.4112 - val_accuracy: 0.3201\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.9540 - accuracy: 0.4222 - val_loss: 2.3278 - val_accuracy: 0.3307\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9483 - accuracy: 0.4241 - val_loss: 2.3503 - val_accuracy: 0.3269\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9283 - accuracy: 0.4228 - val_loss: 2.3851 - val_accuracy: 0.3210\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.9179 - accuracy: 0.4225 - val_loss: 2.3807 - val_accuracy: 0.3240\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.9298 - accuracy: 0.4338 - val_loss: 2.3233 - val_accuracy: 0.3307\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8682 - accuracy: 0.4325 - val_loss: 2.4209 - val_accuracy: 0.3249\n",
      "Epoch 50/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8855 - accuracy: 0.4371 - val_loss: 2.3450 - val_accuracy: 0.3366\n",
      "Epoch 51/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8778 - accuracy: 0.4345 - val_loss: 2.3381 - val_accuracy: 0.3366\n",
      "Epoch 52/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8856 - accuracy: 0.4313 - val_loss: 2.3325 - val_accuracy: 0.3259\n",
      "Epoch 53/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8784 - accuracy: 0.4313 - val_loss: 2.3818 - val_accuracy: 0.3327\n",
      "Epoch 54/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8409 - accuracy: 0.4510 - val_loss: 2.3633 - val_accuracy: 0.3278\n",
      "Epoch 55/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8535 - accuracy: 0.4397 - val_loss: 2.3329 - val_accuracy: 0.3375\n",
      "Epoch 56/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8447 - accuracy: 0.4445 - val_loss: 2.3483 - val_accuracy: 0.3307\n",
      "Epoch 57/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8217 - accuracy: 0.4455 - val_loss: 2.3683 - val_accuracy: 0.3249\n",
      "Epoch 58/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.8043 - accuracy: 0.4458 - val_loss: 2.3487 - val_accuracy: 0.3346\n",
      "Epoch 59/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8277 - accuracy: 0.4694 - val_loss: 2.3202 - val_accuracy: 0.3366\n",
      "Epoch 60/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8190 - accuracy: 0.4594 - val_loss: 2.3938 - val_accuracy: 0.3424\n",
      "Epoch 61/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.8117 - accuracy: 0.4633 - val_loss: 2.3621 - val_accuracy: 0.3269\n",
      "Epoch 62/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8064 - accuracy: 0.4623 - val_loss: 2.3547 - val_accuracy: 0.3482\n",
      "Epoch 63/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.8004 - accuracy: 0.4646 - val_loss: 2.4062 - val_accuracy: 0.3414\n",
      "Epoch 64/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7802 - accuracy: 0.4636 - val_loss: 2.3632 - val_accuracy: 0.3259\n",
      "Epoch 65/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7778 - accuracy: 0.4691 - val_loss: 2.3957 - val_accuracy: 0.3259\n",
      "Epoch 66/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7785 - accuracy: 0.4633 - val_loss: 2.3699 - val_accuracy: 0.3327\n",
      "Epoch 67/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7838 - accuracy: 0.4600 - val_loss: 2.4028 - val_accuracy: 0.3240\n",
      "Epoch 68/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.7433 - accuracy: 0.4746 - val_loss: 2.3864 - val_accuracy: 0.3278\n",
      "Epoch 69/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.7391 - accuracy: 0.4720 - val_loss: 2.3907 - val_accuracy: 0.3249\n",
      "Epoch 70/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7284 - accuracy: 0.4850 - val_loss: 2.4363 - val_accuracy: 0.3307\n",
      "Epoch 71/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7517 - accuracy: 0.4830 - val_loss: 2.4273 - val_accuracy: 0.3346\n",
      "Epoch 72/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.7416 - accuracy: 0.4710 - val_loss: 2.4590 - val_accuracy: 0.3424\n",
      "Epoch 73/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.7496 - accuracy: 0.4743 - val_loss: 2.3820 - val_accuracy: 0.3385\n",
      "Epoch 74/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6946 - accuracy: 0.5008 - val_loss: 2.4053 - val_accuracy: 0.3307\n",
      "Epoch 75/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6995 - accuracy: 0.4879 - val_loss: 2.4055 - val_accuracy: 0.3472\n",
      "Epoch 76/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6962 - accuracy: 0.4930 - val_loss: 2.4184 - val_accuracy: 0.3337\n",
      "Epoch 77/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6629 - accuracy: 0.4992 - val_loss: 2.3891 - val_accuracy: 0.3521\n",
      "Epoch 78/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6802 - accuracy: 0.4934 - val_loss: 2.4326 - val_accuracy: 0.3278\n",
      "Epoch 79/100\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 1.6997 - accuracy: 0.4888 - val_loss: 2.3782 - val_accuracy: 0.3482\n",
      "Epoch 80/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6531 - accuracy: 0.4966 - val_loss: 2.4904 - val_accuracy: 0.3366\n",
      "Epoch 81/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6704 - accuracy: 0.4905 - val_loss: 2.5249 - val_accuracy: 0.3210\n",
      "Epoch 82/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6750 - accuracy: 0.5027 - val_loss: 2.4081 - val_accuracy: 0.3482\n",
      "Epoch 83/100\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 1.6443 - accuracy: 0.5057 - val_loss: 2.3905 - val_accuracy: 0.3317\n",
      "Epoch 84/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6301 - accuracy: 0.5128 - val_loss: 2.4424 - val_accuracy: 0.3307\n",
      "Epoch 85/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6491 - accuracy: 0.5086 - val_loss: 2.4352 - val_accuracy: 0.3395\n",
      "Epoch 86/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6342 - accuracy: 0.5011 - val_loss: 2.4199 - val_accuracy: 0.3414\n",
      "Epoch 87/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6282 - accuracy: 0.5128 - val_loss: 2.4193 - val_accuracy: 0.3249\n",
      "Epoch 88/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6139 - accuracy: 0.5160 - val_loss: 2.4405 - val_accuracy: 0.3472\n",
      "Epoch 89/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6093 - accuracy: 0.5186 - val_loss: 2.4728 - val_accuracy: 0.3356\n",
      "Epoch 90/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6010 - accuracy: 0.5199 - val_loss: 2.4160 - val_accuracy: 0.3434\n",
      "Epoch 91/100\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 1.6042 - accuracy: 0.5222 - val_loss: 2.4283 - val_accuracy: 0.3404\n",
      "Epoch 92/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5867 - accuracy: 0.5196 - val_loss: 2.4539 - val_accuracy: 0.3346\n",
      "Epoch 93/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5739 - accuracy: 0.5254 - val_loss: 2.5410 - val_accuracy: 0.3220\n",
      "Epoch 94/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6378 - accuracy: 0.5134 - val_loss: 2.4526 - val_accuracy: 0.3385\n",
      "Epoch 95/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5782 - accuracy: 0.5180 - val_loss: 2.4716 - val_accuracy: 0.3366\n",
      "Epoch 96/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.6027 - accuracy: 0.5183 - val_loss: 2.4728 - val_accuracy: 0.3230\n",
      "Epoch 97/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5716 - accuracy: 0.5257 - val_loss: 2.4898 - val_accuracy: 0.3317\n",
      "Epoch 98/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5312 - accuracy: 0.5328 - val_loss: 2.5369 - val_accuracy: 0.3240\n",
      "Epoch 99/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5463 - accuracy: 0.5212 - val_loss: 2.4759 - val_accuracy: 0.3463\n",
      "Epoch 100/100\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.5261 - accuracy: 0.5370 - val_loss: 2.5363 - val_accuracy: 0.3366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda9a40c050>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# built large model\n",
    "vnn = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape=(1024,)),\n",
    "      tf.keras.layers.Dense(512, activation='elu'),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(24, activation='softmax')\n",
    "      ], name=\"vnn\")\n",
    "\n",
    "# optimizer\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, clipnorm=1.0)\n",
    "opt = tf.keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "# compile model\n",
    "vnn.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "# train model\n",
    "vnn.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRAP: 0.5029935654623648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.19      0.17        16\n",
      "           1       0.20      0.08      0.11        25\n",
      "           2       0.52      0.42      0.47        26\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.31      0.41      0.35        41\n",
      "           5       0.35      0.11      0.17        55\n",
      "           6       0.44      0.36      0.39        39\n",
      "           7       0.27      0.07      0.11        56\n",
      "           8       0.38      0.55      0.45        49\n",
      "           9       0.16      0.24      0.19        38\n",
      "          10       0.28      0.12      0.17        42\n",
      "          11       0.10      0.08      0.09        26\n",
      "          12       0.43      0.48      0.45        42\n",
      "          13       0.43      0.53      0.47        17\n",
      "          14       0.20      0.04      0.07        23\n",
      "          15       0.38      0.38      0.38        48\n",
      "          16       0.36      0.33      0.35        27\n",
      "          17       0.38      0.41      0.39       101\n",
      "          18       0.00      0.00      0.00        14\n",
      "          19       0.54      0.28      0.37        25\n",
      "          20       0.19      0.33      0.25        60\n",
      "          21       0.06      0.04      0.05        25\n",
      "          22       0.17      0.04      0.07        23\n",
      "          23       0.41      0.62      0.49       193\n",
      "\n",
      "    accuracy                           0.34      1031\n",
      "   macro avg       0.28      0.25      0.25      1031\n",
      "weighted avg       0.32      0.34      0.31      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_lrap_keras(X_val, y_one_hot_val, vnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
