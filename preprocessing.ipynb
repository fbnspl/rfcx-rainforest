{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fabianseipel/aic/data/rfcx-species-audio-detection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sr\": 48000,\n",
      "    \"audio_length\": 1,\n",
      "    \"mono\": true,\n",
      "    \"n_mels\": 64,\n",
      "    \"n_fft\": 2000,\n",
      "    \"hop_length\": 500,\n",
      "    \"win_length\": 2000,\n",
      "    \"window\": \"hann\",\n",
      "    \"center\": true,\n",
      "    \"pad_mode\": \"reflect\",\n",
      "    \"power\": 2.0,\n",
      "    \"classes\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5,\n",
      "        6,\n",
      "        7,\n",
      "        8,\n",
      "        9,\n",
      "        10,\n",
      "        11,\n",
      "        12,\n",
      "        13,\n",
      "        14,\n",
      "        15,\n",
      "        16,\n",
      "        17,\n",
      "        18,\n",
      "        19,\n",
      "        20,\n",
      "        21,\n",
      "        22,\n",
      "        23\n",
      "    ],\n",
      "    \"n_frames\": 97,\n",
      "    \"input_shape\": [\n",
      "        64,\n",
      "        97,\n",
      "        1\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# load train csv\n",
    "df_gt = pd.read_csv(data_path + 'train_tp.csv')\n",
    "\n",
    "# get all unique ids\n",
    "spec_ids = sorted(list(set(list(df_gt['species_id']))))\n",
    "\n",
    "# best-practice: write down your preprocessing config in a dictonary\n",
    "config = {'sr': 48000, \n",
    "          'audio_length': 1,\n",
    "          'mono': True,\n",
    "          'n_mels': 64,\n",
    "          'n_fft': 2000,\n",
    "          'hop_length': 500,\n",
    "          'win_length': 2000,\n",
    "          'window': 'hann',\n",
    "          'center': True,\n",
    "          'pad_mode': 'reflect',\n",
    "          'power': 2.0,\n",
    "          'classes': spec_ids\n",
    "         }\n",
    "\n",
    "# save number of frames from length in samples divided by fft hop length\n",
    "config['n_frames'] = int(config['sr']*config['audio_length']/config['hop_length']) + 1\n",
    "\n",
    "# save input shape for model\n",
    "config['input_shape'] = (config['n_mels'], config['n_frames'], 1)\n",
    "\n",
    "# save config \n",
    "with open('data/yamnet_config.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n",
    "\n",
    "# pretty print json\n",
    "print(json.dumps(config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mel-filter matrix\n",
    "mel_filter = librosa.filters.mel(config['sr'], \n",
    "                                 config['n_fft'], \n",
    "                                 n_mels=config['n_mels'], \n",
    "                                 fmin=0.0, \n",
    "                                 fmax=None, \n",
    "                                 htk=False, \n",
    "                                 norm='slaney', \n",
    "                                 dtype=np.float32)\n",
    "\n",
    "\n",
    "def folder_name_to_one_hot(file_path):\n",
    "    \n",
    "    # for example: _data/TinyUrbanSound8k/train/siren/157648-8-0-0_00.wav\n",
    "    label = Path(file_path).parts[-2]\n",
    "    label_idx = classes.index(label)\n",
    "    \n",
    "    # get one hot encoded array\n",
    "    one_hot = tf.one_hot(label_idx, len(config['classes']), on_value=None, off_value=None, \n",
    "                         axis=None, dtype=tf.uint8, name=None)\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def audiopath_to_melspec(file_path):\n",
    "    # load audio data \n",
    "    y, _ = librosa.core.load(file_path, sr=config['sr'], mono=config['mono'], offset=0.0, duration=None, \n",
    "                             dtype=np.float32, res_type='kaiser_best')\n",
    "\n",
    "    # calculate stft from audio data\n",
    "    stft = librosa.core.stft(y, n_fft=config['n_fft'], hop_length=config['hop_length'], \n",
    "                             win_length=config['win_length'], window=config['window'], \n",
    "                             center=config['center'], dtype=np.complex64, pad_mode=config['pad_mode'])\n",
    "\n",
    "    # filter stft with mel-filter\n",
    "    mel_spec = mel_filter.dot(np.abs(stft).astype(np.float32) ** config['power'])\n",
    "    \n",
    "    # add channel dimension for conv layer  compatibility\n",
    "    mel_spec = np.expand_dims(mel_spec, axis=-1)\n",
    "    \n",
    "    mel_spec_frames = librosa.util.frame(mel_spec, frame_length=2048, hop_length=64)\n",
    "    \n",
    "    return mel_spec_frames\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # path string is saved as byte array in tf.data.dataset -> convert back to str\n",
    "    if type(file_path) is not str:\n",
    "        file_path = file_path.numpy()\n",
    "        file_path = file_path.decode('utf-8')\n",
    "    \n",
    "    # get malspec\n",
    "    mel_spec = audiopath_to_melspec(file_path)\n",
    "    \n",
    "    # get ground truth from file_path string\n",
    "    one_hot = folder_name_to_one_hot(file_path)\n",
    "    \n",
    "    return mel_spec, one_hot\n",
    "\n",
    "\n",
    "# there is a TF bug where we get an error if the size of the tensor from a py.function is not set manualy\n",
    "# when called from a map()-function.\n",
    "def preprocessing_wrapper(file_path):\n",
    "    mel_spec, one_hot = tf.py_function(load_and_preprocess_data, [file_path], [tf.float32, tf.uint8])\n",
    "    \n",
    "    mel_spec.set_shape([config['n_mels'], config['n_frames'], 1])\n",
    "    one_hot.set_shape([len(config['classes'])])\n",
    "    return mel_spec, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5761, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_spec = audiopath_to_melspec('yamnet/0a65cc78c.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# folder with the training data\n",
    "train_files = data_path + 'train/*.flac'\n",
    "# define a dataset of file paths\n",
    "train_dataset = tf.data.Dataset.list_files(train_files)\n",
    "# run the preprocessing via map\n",
    "train_dataset = train_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "# save dataset to disk\n",
    "!rm -rf ./_data/TinyUrbanSound8k_train\n",
    "tf.data.experimental.save(dataset=train_dataset, path=f'./_data/TinyUrbanSound8k_train', compression='GZIP')\n",
    "# show tensor types and shapes in dataset (we need this to load the dataset later)\n",
    "print(train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest",
   "language": "python",
   "name": "rainforest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
